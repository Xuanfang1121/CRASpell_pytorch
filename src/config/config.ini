[strings]
# Mode : train, test, serve
train_data_path = ./data/sighan/train_demo.txt
test_data_path = ./data/sighan/test_demo.txt
multierror_data_path = ./data/sighan/sighan15_multierror.txt

same_py_file = ./data/confusions/same_pinyin.txt
simi_py_file = ./data/confusions/simi_pinyin.txt
stroke_file = ./data/confusions/same_stroke.txt

# Pretrain model
pretrain_model_path = D:/Spyder/pretrain_model/transformers_torch_tf/bert-base-chinese/
pretrain_model_type = bert-base

# gpu ids
visible_gpus = -1
# save para
output_path = ./output/
model_name = model.pt

[ints]
# model para
max_seq_length = 128
epochs = 2
batch_size = 2
dev_batch_size = 2
seed = 1234
local_rank = 0
eval_interval = 2
require_improvement = 500
pre_epoch_step_print = 200

[floats]
learning_rate = 1e-5
dropout_rate = 0.2

[bools]
is_training = True
